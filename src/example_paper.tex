%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2016 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2016,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% qdeee: for mathbb
\usepackage{amsmath}
\usepackage{amssymb}

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% For sub-files
\usepackage{standalone}

\usepackage{multicol}
\usepackage{multirow} % http://ctan.org/pkg/multirow
\usepackage{hhline} % http://ctan.org/pkg/hhline

% For plots
\usepackage{epstopdf}
%\usepackage{color}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2017} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
% \usepackage[accepted]{icml2017}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Using Matrix Factorization Methods for Multiclass Classification tasks}

\begin{document} 

\twocolumn[
\icmltitle{Using Matrix Factorization Methods for Multiclass Classification Tasks}
            

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2017
% package.

% list of affiliations. the first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% you can specify symbols, otherwise they are numbered in order
% ideally, you should not use this facility. affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ruslan Solovev}{equal,to}
\icmlauthor{Igor Kuralenok}{equal,to,goo}
\end{icmlauthorlist}

\icmlaffiliation{to}{University of Torontoland, Torontoland, Canada}
\icmlaffiliation{goo}{Googol ShallowMind, New London, Michigan, USA}

\icmlcorrespondingauthor{Ruslan Solovev}{solovevr@gmail.com}
\icmlcorrespondingauthor{Igor Kuralenok}{ikuralenok@gmail.com}


% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{multinomial logistic regression, matrix factorization, gradient boosting}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
%\footnotetext{hi}

\begin{abstract} 
In this paper we introduce a new approach to multiclassification based on simultaneous build of all scoring functions in multinomial logistic regression framework. The proposed algorithm provides more lightweight decision function while being on par with state-of-the-art methods in terms of prediction quality. The method is based on multinomial logistic regression and gradient boosting. The first part allows the researcher not to bother balancing of different classes in dataset, and the second give her the opportunity to control the time to model quality ratio.
\end{abstract} 

\section{Introduction}
\label{introduction}
Classification onto more than two classes is very natural setting for many tasks. Among others we should mention text classification, object recognition, protein folds etc. There are four principal approaches to this problem known from the literature: one-vs-rest, multinomial logistic regression \cite{GLM}, multiclass boosting \cite{journals/jmlr/MukherjeeS13} and using complex system of binary classifiers with associated modeling matrix \cite{Allwein00reducingmulticlass}.

Each of these families have their properties and depending on the task could be more or less effective. The simplicity of one vs. rest makes it the most popular method in everyday work of ML practician. On the other hand this simplicity in training process is balanced by need of balancing the result scoring functions either by count of the representatives of each class or by other methods. Multinomial logistic regression based methods are the opposite extreme case. They are much easier to prepare for learning---scoring functions will be comparable by the design, but it takes ages to learn a strong model. Multiclass boosting allows us to split this process building one weak classifier at a time balancing the weights of examples, but we still need to solve multi-classification problem on each step. Modeling matrix approach generalize the one-vs-rest allowing one to build binary classifiers complimentary to each other. This way allows us to build smaller number of decision functions than the $K-1$, where $K$ is number of classes. There are some works about the building of the modeling matrix \cite{Zhao_sparseoutput, modelmatrix2}, however there is no good way to build this matrix universally and it should be constructed in ad-hoc manner in most of the cases.

Our goal is to combine described approaches to get the method that is as simple as one-vs-rest, able to work with lot of classes, less sensitive to class imbalance, has light decision function to be used online. To achieve these properties we do the gradient boosting for multinomial logistic regression to find a decision function in form of single ensemble. The multinomial logistic regression particularly allows us to forget about class imbalance; gradient boosting allows one to control the time to model quality ratio; and the simplicity of the decision function allows us to convert multi-classification into series of regression tasks.

% The fo

% Our contribution as follows:
% \begin{itemize}
% \item We propose the GradFac multiclassification algorithm that is based on gradient boosting and matrix factorization. We show that in most cases it can reduce total count of weak models without sufficient quality degradation.
% \item We describe the main disadvantage of the new algorithm and propose two fixes: matrix columns bootstrapping and \emph{ElasticNet} factorization. 
% \item We apply the GradFac algorithm to the classic gradient boosted tree classifier on benchmark datasets.
% \end{itemize}



\section{Motivation}

Many algorithms in ML are focused around classification or regression tasks and the idea of employing them for multiclassification looks attractive. The modeling matrix approach formulated by Allwein, Schapire and Singer \cite{Allwein00reducingmulticlass} allows one to split this complex task into binary classification subtasks. Unfortunately the elements of the modeling matrix must be from set of $\{-1,0,1\}$ and this fact makes the optimization on this matrix much more difficult \cite{Zhao_sparseoutput, modelmatrix2}. We want to get rid of this limitation to simplify the optimization task. Another important property of this approach is that we can use when number of classes is significant and it is next to impossible to train scoring function for each of them. In this case we ``code'' the class by modeling matrix row and, using results of the binary classifiers, are able to estimate the this class probability.

We will look for decision function in the class of the following functions:
\begin{equation}
H_c(x) = \sum_t b_{ct} h_t(x) 
\end{equation}
where $H_c(x)$ is a scoring function for class $c$ at point $x$, $b_{ct}$ is a scalar value, associated with the class $c$ at step $t$, and $h_t(x)$ is some real-valued function of $x$. The probability of class $c$ look exactly like one in multinomial logistic regression:
\begin{equation}
  P(Y = c \arrowvert x, H) =
  \begin{cases}
    \frac{ e^{H_{c}(x)} }
       { 1+\sum_{j=1}^{K-1} e^{H_{j}(x)} }
    , & c \in \{1, \ldots, K-1 \} \\

    \frac{ 1 }
       { 1 + \sum_{j=1}^{K-1} e^{H_{j}(x)} }
    , & c=K
  \end{cases}\label{eq:MLR_model}
\end{equation}
where $P(Y = c \arrowvert x, H)$ is desired probability of the class $c \in \{1\ldots K\}$ for the query $x$.

This type of decision function look very similar to those using modeling matrix: $\mathbb{B} = \{b_{ct}\}$ form the matrix itself, and the $h_t$ are some regression task solutions:
\begin{equation}
h_{t+1} = \arg \min_h \|h(X) - r_t\|.
\end{equation}
Our task is to find proper series of $(b_t, r_t)$. We use modification of the multinomial logistic regression gradient boosting for this.

\subsection{Multinomial logistic regression}
The boosting of multinomial logistic regression is a well studied topic \cite{Friedman98additivelogistic}. The multinomial regression models discriminative surfaces between classes in form of $H_{c_1}(x)=H_{c_2}(x)$, this brings probability of the class into form of (\ref{eq:MLR_model}) \cite{GLM}. The boosting approach implies the ensemble form of scoring function $H_c(x) = \sum_t h_{ct}(x)$. The target function is the following:
\begin{multline*}
	L(X\arrowvert H) = \sum_{(x,y) \in X} \log P(Y = y \arrowvert x, H) = \\
	= \sum_{(x,y) \in X} \log \frac{ I\{y \ne K \}e^{H_y(x)} + I\{y=K\} }{ 1+\sum_{c=1}^{K-1} e^{H_c(x)} }
\end{multline*}
In this case $X$ is not only features matrix, but entire set of $(x, y)$ precedents. On each step we want $h_{t + 1}(X)$ to be aligned with the $\frac{\partial L(X|H)}{\partial H_c(x)}(H_t(X))$. For simplicity one can interpret $\frac{\partial L(X|H)}{\partial H_c(x)}(H_t(X))$ as a matrix $R_t$ of size $|X|\times K-1$. Then it is time to optimize $h_{c,t+1}$:
\begin{equation}
h_{c,t+1} = \arg \min_h \|h_c(X) - r_{ct}\|_2^2
\label{eq:MLR_boosting_step}
\end{equation}
where $r_c$ is a column of the matrix representation of gradient $R$. At this step we need to build the regression $K-1$ times and this part is the most computationally intensive. We have described the independent variant of the optimization, but it can be enhanced even further by dropping the independence assumption for certain types of decision functions (such as regression trees).

\subsection{The idea of FMCB}
The main difference from the multinomial regression boosting is the form of decision function. We want to simultaneously optimize (\ref{eq:MLR_boosting_step}) for all classes. But the $l_2$ target function is additive and we can rewrite the optimization in the following form:
\begin{equation}
(h_{t+1},b_{t+1}) = \arg \min_{h,b} \sum_c \|b_ch(X) - r_{ct}\|_2^2
\end{equation}
where $b_{t+1}$---column of the future modeling matrix. At this point we assume that this optimization could be split into two steps:
\begin{equation}\begin{array}{l}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F^2 \\
h_t	= \arg \min_{h} \|h(X) - r_{t+1}\|_2^2
\end{array}\end{equation}
According to the Eckart-Young-Mirsky theorem \cite{Eckart1936} there is exact solution of the first optimization. The second one is just a regression problem. The split assumption is correct when $h$ is flexible enough to bring the $\|h(X) - r_{t+1}\|$ to zero. In most of the cases this is not true and this step won't allow us to use results of the boosting convergence analysis \cite{??}. In the next section
\label{sec:fmcb_idea}


\section{Factorized MultiClass Boosting}

The proposed algorithm optimizes the likelihood function:
\begin{multline*}
	L(X\arrowvert H) = \sum_{(x,y) \in X} \log \frac{ I\{y \ne K \}e^{H_y(x)} + I\{y=K\} }{ 1+\sum_{c=1}^{K-1} e^{H_c(x)} }.
\end{multline*}
The decision takes form of vector function:
\begin{equation}
H(x) = \sum_t b_{t} h_t(x) 
\end{equation}
where $b_t$ are vectors of $K-1$ components and $h_t$ are real functions of $x$. The optimization is done iteratively. $H_c(x)$ are treated as independent variables and therefore one can get gradient of target function in terms of these variables. It is possible to present this gradient vector as a matrix each column of this matrix presents gradient vector of the appropriate class scoring function:
\begin{equation}
\label{eq:grad_matrix}
\nabla L = 
\left(
\begin{array}{ccc}
	  \frac{ \partial L }{ \partial H_{1}(x_{1}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial H_{K-1}(x_{1}) } \\

	  \vdots & \ddots & \vdots\\

	  \frac{ \partial L }{ \partial H_{1}(x_{|X|}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial H_{K-1}(x_{|X|}) }
\end{array}
\right)_{|X| \times (K-1)}
\end{equation}

Each step of optimization is done as close to the $R_t = \nabla L(H_t(X))$ as possible. To do so we factorize the matrix form of the gradient $R$ by rank $1$ matrix $b h(X)^T$ using Frobenius distance as the metric:
\begin{equation}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F^2
\label{eq:factorization_step}
\end{equation}

According to the Eckart-Young-Mirsky theorem \cite{Eckart1936}, solving (\ref{eq:factorization_step}) means finding the left and the right singular vectors of $R_t$ associated with the largest singular value of $R_t$. Therefore, one may apply the following algorithm: 
\begin{enumerate}
	\item Evaluate the singular decomposition of gradient's matrix: $R = U \Sigma V^T$
	\item Take the largest singular value $\sigma_{1}$ and associated singular vectors $u$ and $v$.
	\item Return $\overline{u}={\sigma_{1}}{\Vert v \Vert}_{2}u$ and $\overline{v}=\frac{1}{\Vert v \Vert}_{2}v$ as solution.
\end{enumerate}
However, experiments show that starting from the some iteration, singular values become too close to each other and choice of singular vectors associated with the largest singular value becomes non-trivial. It leads to factorization error growth because the single pair of the left and the right singular vectors is no longer meaningful characteristic of the matrix. We call this negative effect "the spreading of singular values", as the matrix is spreading across several pairs of singular vectors. To overcome this difficulty we have introduced the bias on each step. In the following chapters the implementation of the bias in form of prior (and appropriate regularization) and introduction of the noise into data will be presented.

From the solutions family we choose the pair where $\|b_{t+1}\|_2 = 1$. To find the decision ensemble term $h_{t+1}$ minimization of the distance with factorization component $r_{t+1}$ is performed:
\begin{equation}
h_{t+1}	= \arg \min_{h} \|h(X) - r_{t+1}\|
\label{eq:minimization_step}
\end{equation}
For our experiments we have used modification of the CART algorithm for oblivious trees \cite{Gulin_winningthe} at this step.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/factorization_error_rate.jpg}}
\caption{Factorization error rate growth with number of iterations of FMCB.}
\end{center}
\label{fig:factorization-effectiveness}
\vskip -0.2in
\end{figure}

\subsection{Bias in factorization}
As stated before, the intuition tells that factorization effectiveness will be reduced with each step. Fig.~\ref{fig:factorization-effectiveness} illustrates this effect on example of segment data set (see Sec.\ref{datasets} for details). Factorization gives us the best approximation of $R_t$ in class of rank 1 matrices, so we need to change the optimization goal. There are at least two different approaches to this task: introducing noise into data or biasing the solution by some prior.

\paragraph{Regularization (FMCB-EN)} % (fold)
\label{par:regularization}

% paragraph paragraph_name (end)
In this approach we are to define what kind of solutions are preferred above the others. The modeling matrix column structure gives us idea on this: each class should be either totally excluded or have positive/negative label. In our terms this means sparsity of $b_t$ vector. The most popular prior in this case is Laplacian which gives us $l_1$ regularization term in regression task. On the other hand if we let the $r$ vector grow, this regularization won't be effective because module of these vectors are balanced. To limit the $r$ grows we introduce normal prior and $l_2$ regularization on $r$ term. The final task takes the following form:
\begin{multline}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F + \lambda_1 \|b\|_1 + \lambda_2 \|r\|_2
\label{eq:factorization_l1}
\end{multline}
We employ alternating least squares idea [ref to ALS] for solving (\ref{eq:factorization_l1}). Both steps of the algorithm are similar to each other, lets suppose that $r$ is fixed:
\begin{multline*}
	\hat{b} = \arg\min_{b}\|R_t-br^T\|_2^{2} + \lambda_1 \|b\|_1 + \lambda_2 \|r\|_2^2 \\
	= \arg\min_{b}\sum_{c,i}\left(R_{tci}-b_cr_i\right)^{2} + \lambda_1 \|b\|_1
	\label{eq:elastic-net-argmin}
\end{multline*}
Therefore, we have reduced the initial problem to the linear regression with either $l_1$ or $l_2$ (in case of $r$) regularization, that could be generalized to \emph{Elastic-Net}. Indeed, it can be rewritten to canonical form:
 \begin{equation*}
x^{*}=\arg\min\Vert y-Ax\Vert_{2}^{2}+\lambda_{1}\Vert x\Vert_{2}^{2}+\lambda_{2}\Vert x\Vert_{1},\label{eq:elastic-net-canon-argmin}
\end{equation*}
where $A \in \mathbb{R}^{|X|(K-1)\times |X|}$ and $y \in \mathbb{R}^{|X|(K-1)}$:
\[
A =
\begin{pmatrix}
	b_{1}     		& 				&		  \\
	\vdots			& \mathbb{O}  	&		  \\
	b_{K-1}			& 				&		  \\
					& \ddots		&		  \\
					&   			& b_{1}	  \\
					& \mathbb{O}	& \vdots  \\
					& 				& b_{K-1}
\end{pmatrix},
y=\begin{pmatrix}\begin{array}{l}
	\nabla R_{t1,1}		\\
	\vdots				\\
	\nabla R_{t1,K-1}	\\

	\vdots				\\
	
	R_{t|X|,1}		\\
	\vdots				\\
	R_{t|X|,K-1}
\end{array}\end{pmatrix}
\]
Detailed algorithm for \emph{Elastic-Net} problem could be found at \cite{elasticnet05} or \cite{Hastie_theelements}.

\paragraph{Columns bootstrapping (FMCB-BS)}
We employ statistical bootstrap idea \cite{Efron1992bootstrap}. On each iteration we assign random integer weights to columns of the gradient's matrix. It ensures that singular values will be "shake-up" and consequently it particularly protects us from the problem described above. Required weights could be generated by discrete random variable $\xi$ that has a Poisson distribution with $\lambda = 1$. Due to the fact that $\mathbb{E} \xi = 1$, this weighing approach has a simple physical meaning: in the most of cases we consider all columns of the gradient's matrix but sometimes we amplify ($\xi > 1$) or mute ($\xi = 0$) some of them.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/cn.tex}}
\caption{Condition number of the gradient matrix during training GF and GFEN models on \emph{segmentation} dataset.}
\end{center}
\label{fig:condition_number}
\vskip -0.2in
\end{figure}

\paragraph{Effect of the bias}
To evaluate effect of the bias introduction we track the condition number of the matrix $R_t$ which determines the quality of the factorization. The Fig.~\ref{fig:condition_number} shows the effect of our manipulations. As one can see, effect of bias introduction is fairy small and looking for more effective ways to deal with factorization quality degradation is one of the most promising directions of the future work. Interesting fact is that after certain number of iterations the condition number starts to grow. The norm of the gradient at that point starts to be so low, that successive iteration gradients are not aligned with each other. At that point original algorithm starts to be more precise. The problem is that this point could be not reached at some collections.

\subsection{Columns bootstrapping}
We employ statistical bootstrap idea \cite{Efron1992bootstrap}. On each iteration we assign random integer weights to columns of the gradient's matrix. It ensures that singular values will be "shake-up" and consequently it particularly protects us from the problem described above. Required weights could be generated by discrete random variable $\xi$ that has a Poisson distribution with $\lambda = 1$. Due to the fact that $\mathbb{E} \xi = 1$, this weighing approach has a simple physical meaning: in the most of cases we consider all columns of the gradient's matrix but sometimes we amplify ($\xi > 1$) or mute ($\xi = 0$) some of them.

\begin{algorithm}[tb]
   \caption{Factorized MultiClass Boosting}
   \label{alg:boost_mlr}
\begin{algorithmic}
   \STATE {\bfseries Input:} step $\alpha$, iterations count $T$.
   \STATE $H^{(0)}(x):= \mathbb{O} \in \mathbb{F}^{K-1}$ \COMMENT{initial zero model}
   \STATE $\overline{x}^{(0)} := \mathbb{O} \in \mathbb{R}^{N \times (K-1)}$ \COMMENT{initial cursor}

   \FOR{$t=1$ {\bfseries to} $T$}
   		\STATE Evaluate $\nabla L$ at $\overline{x}^{(t-1)}$ using (\ref{eq:partial_L}).
   		\FOR{$j=1$ {\bfseries to} $K-1$}
   			\STATE Train weak model $h_{j}^{(t)}(x)$ using $\{X,\nabla L^{[j]}\}$ as a training set and MSE as a target function:
   			\[
				h_{j}^{(t)}(x)=\arg\min_{h \in \mathbb{F}} \sum_{i=1}^{N}\left(\nabla L_{ij}-h(x_{i})\right)^{2}
			\]
		\ENDFOR
		\STATE Update model: $H^{(t)}(x)=H^{(t-1)}(x)+\alpha h^{(t)}(x)$.
		\STATE Update cursor: $\overline{x}^{t} = \overline{x}^{(t-1)} + h^{(t)}(X)$.
   \ENDFOR
   
\end{algorithmic}
\end{algorithm}

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/cn.tex}}
\caption{Gradient norm by iterations count for all proposed modifications.}
\end{center}
\label{fig:gradient_norm}
\vskip -0.2in
\end{figure}

\paragraph{Convergence}
As stated in Sec.~\ref{sec:fmcb_idea} two step optimization of the $R_t$ does not allow us to say anything on convergence of the proposed method. The other problem is that factorization error rate is pretty high (see Fig.~\ref{fig:factorization-effectiveness}). Considering it in couple with the residual of the (\ref{eq:minimization_step}) the effective direction of the $b h_t(X)^T$ could be far from original $R_t$ and lead to $H$ quality reduction. On the other hand we have easy way to ensure that this reduction have not happen yet: if $\|R_{t+1}\|_F <\|R_{t+1}\|_F$ than the last step was successful. This statement could be used as a stop condition for the algorithm. In the Fig.~\ref{fig:gradient_norm} one can see the drop of the gradient norm with the iterations count for proposed modifications of the algorithm.


\section{Experiments} \label{experiments}
Let us remind that our goal is to maximize total weak models count to prediction quality ratio. In each experiment we compare accuracy that could be reached with fixed count of weak models. We have chosen two competing methods that could use the same weak model optimization: one vs. rest and multinomial logistic regression. This approach gives us the opportunity to compare the influence of the learning procedure but not the quality of the base/weak models.

We have tested the \emph{Factorized MultiClass Boosting} algorithm with data from the UCI repository \cite{uciRepo}. Table \ref{datasets} shows characteristics of different datasets used. Our goal was to compare proposed method and its competitors in principally different setups and chosen datasets allow us to do that.

\begin{table}[t]
\caption{Statistics for the classification datasets.}
\label{datasets}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lrrrr}
\hline
\abovespace\belowspace
Data set & Examples & Features & Classes \\
\hline
\abovespace
wine     		& 178 	& 17 	& 3     \\
letter    		& 20000 & 16 	& 26 	\\
MNIST     		& 60000 & 785 	& 10    \\
pendigits 		& 7494 	& 21 	& 10 	\\
segmentation    & 2300 	& 23 	& 7     \\
\hline
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

\input{experiments.tex}
 
The results are presented in Table 2. Each cell contains mean and standard deviation of the accuracy evaluated with 10-folds cross-validation. We find that proposed algorithm FMCB almost always achieves the highest score compared to other models. Also we see that in the most of the cases we could sufficiently reduce the weak models count for FMCB variations methods and stay competitive with state-of-the-art methods in terms of prediction quality.

\section{Conclusions and future work}
In this paper we have presented new approach to multiclass classification problem. The proposed algorithms are able to be statistically significant better than multinomial logistic regression boosting and one vs. rest using the same weak learners. This advantage persists over collections we used for testing. The number of test collections does not allow us to say that the proposed method is always better in terms of prediction quality, but we have not found evidence of the opposite statement. The resulting decision function is computationally more lightweight than one of existing methods due to its' single ensemble nature. The computational difficulty of learning procedure is on par with one vs. rest and could be optimized even further, using more effective approximate factorization techniques. FMCB method is able to work with lot of classes and the only limitation is computational complexity of the matrix form of gradient factorization procedure.

Two major problems of the proposed approach were discovered:
\begin{itemize}
	\item the factorization error rate grows with the iterations count;
	\item because of factorization error and non zero weak optimization residual the method is able to diverge.
\end{itemize}
To overcome the first difficulty we tested two methods of bias introduction in factorization task. The tested methods were able to soften, but not to eliminate the growth of the error rate. During this testing we have found that for certain collections the discovered problem is relevant only for limited number of iterations. The second problem could be practically solved by introduction of the stop condition. We have suggested such a condition and found that we were unable to reach it on test collections.

FMCB method tends to be both easy to use, it does not require thorough data preparation, and effective in terms of computational complexity to prediction quality ratio. We hope it could be used as a ``first attempt'' method for multiclass classification tasks. The implementation of the algorithm could be found on github \cite{github}.

As stated before we see the following directions of further improvement of the method:
\begin{itemize}
	\item factorization error elimination;
	\item further reduction of factorization computational cost.
\end{itemize}
We have described our vision on first problem solutions in the paper and now focus on the second. The matrix $R_t$ often have not even dimensions. In many cases $|X| >> K$ and one can interpret factorization process in probabilistic framework:
$$
\hat{b} = \arg \min_b \mathbb{E}_{r \in R_t}\sum_c\left(b_c \frac{\sum_c r_c}{\sum_c b_c} - r_c\right)^2
$$
This optimization could be done stochastically which is less computationally difficult. Besides the computation cost this allows us not to store $R_t$ matrix which is expansive in terms of memory consumption.
% main advantage of the \emph{GradFac} algorithm is the independence of the number of classes on the training stage: it's only required to train a single model instead of $K-1$ models. However, factorization stage depends on the number of classes. 
% Consider impact of factorization on quality of the final classification model. Obviously, matrix factorization increases total error because of replacement the whole matrix to outer product of two estimated vectors $u$ and $v$. Should we decrease the algorithm's quality on purpose? To answer this question one should remember the ability of the gradient boosting method to accumulate weak models in order to obtain the strong. Therefore, to compensate introduced error, we have to increase boosting iterations count and train some additional weak models (\emph{one} per iteration). 
% Suppose $L(H_{T}(x) \arrowvert X,Y) \le \varepsilon$ is true for the source algorithm after $T_{1}$ iterations and for the \emph{GradFac} algorithm after $T_{2}$ iterations. Note that $T_{1}<T_{2}$ because we need to compensate factorization error. Also note that the source algorithm requires to train $K-1$ weak models and the \emph{GradFac} algorithm requires to train $1$ model. It's hard to say definitely which model includes less weak models count: 
% \[
% \begin{array}{rccc}
% 	\text{Iterations count:}	& T_{1} 				& <		& T_{2} \\
% 	\text{Weak models count:}	& T_{1}\times(K-1) 		& ??	& T_{2}
% \end{array}
% \]
% We will come back to this issue in the experiments section.



% We have introduced in this paper a new multiclassification algorithm GradFac that is based on the idea of gradient's matrix factorization. Experiments demonstrated that our algorithm allows to build up to 3 times easier model than state-of-the-art models like OVR or MLR without quality degradation. Of course, more experiments are needed to better understand applicability limits of this method, especially for tasks with large class count.

% There are several avenues for future research. One of the most simple ideas - variation of considering eigen vectors count (instead of 1). GradFac is also appealing for multi-label tasks because there are several target functions for such tasks \cite{Tsoumakas07multi-labelclassification} that allow to represent their gradients as matrix and consequently allow to apply factorization techniques.

% \clearpage
% Acknowledgements should only appear in the accepted version. 
\section*{Acknowledgments} 


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\nocite{Hastie_theelements}
\nocite{GLM}
\nocite{Friedman98additivelogistic}
\nocite{Friedman00greedyfunction}
\nocite{Zhao_sparseoutput}
\nocite{Allwein00reducingmulticlass}
\nocite{Crammer00onthe}
\nocite{Rifkin04indefense}
\nocite{Lee01algorithmsfor}
\nocite{Koren09matrixfactorization}
\nocite{Hu08collaborativefiltering}
\nocite{Gulin_winningthe}
\nocite{Eckart1936}
\nocite{elasticnet05}
\nocite{Efron1992bootstrap}
%\nocite{multilabel12}
\nocite{uciRepo}

\bibliography{example_paper}
\bibliographystyle{icml2017}

\end{document} 