%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2016 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2016,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% qdeee: for mathbb
\usepackage{amsmath}
\usepackage{amssymb}

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% For sub-files
\usepackage{standalone}

\usepackage{multicol}
\usepackage{multirow} % http://ctan.org/pkg/multirow
\usepackage{hhline} % http://ctan.org/pkg/hhline

% For plots
\usepackage{epstopdf}
%\usepackage{color}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% \AtBeginShipout{%
%   \ifnum\value{page}>1 %
%     \typeout{* Additional boxing of page `\thepage'}%
%     \setbox\AtBeginShipoutBox=\hbox{\copy\AtBeginShipoutBox}%
%   \fi
% }

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2017} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
% \usepackage[accepted]{icml2017}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Factorized MultiClass Boosting}

\begin{document} 

\twocolumn[
\icmltitle{Factorized MultiClass Boosting}
            

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2017
% package.

% list of affiliations. the first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% you can specify symbols, otherwise they are numbered in order
% ideally, you should not use this facility. affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ruslan Solovev}{equal,to}
\icmlauthor{Igor Kuralenok}{equal,to,goo}
\end{icmlauthorlist}

\icmlaffiliation{to}{University of Torontoland, Torontoland, Canada}
\icmlaffiliation{goo}{Googol ShallowMind, New London, Michigan, USA}

\icmlcorrespondingauthor{Ruslan Solovev}{solovevr@gmail.com}
\icmlcorrespondingauthor{Igor Kuralenok}{ikuralenok@gmail.com}


% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{multinomial logistic regression, matrix factorization, gradient boosting}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
%\footnotetext{hi}

\begin{abstract} 
In this paper we introduce a new approach to multiclassification based on simultaneous build of all scoring functions in multinomial logistic regression framework. The proposed algorithm works faster and provides more lightweight decision function while being on par with state-of-the-art methods in terms of prediction quality. The method is based on multinomial logistic regression and gradient boosting. The MLR allows the researcher not to bother balancing classes in dataset, and the boosting approach gives her the opportunity to control trade-off between time and model quality.
\end{abstract} 

\section{Introduction}
\label{introduction}
Classification onto more than two classes is very natural setting for many tasks. Among others we should mention text classification, object recognition, protein folds etc. There are four principal approaches to this problem known from the literature: one vs. rest, multinomial logistic regression \cite{GLM}, multiclass boosting \cite{journals/jmlr/MukherjeeS13} and using complex system of binary classifiers with associated modeling matrix \cite{Allwein00reducingmulticlass}.

Each of these families have their properties and depending on the task could be more or less effective. The simplicity of one vs. rest makes it the most popular method in everyday work of ML practician. On the other hand this simplicity in training process is offset by need of balancing the result scoring functions. This balancing is done either by count of the representatives of each class or by other methods \cite{imbalancing_classes1,imbalancing_classes2}.

Multinomial logistic regression boosting methods are the opposite extreme case. They are much easier to prepare for learning---scoring functions will be comparable by the design \cite{mlr_imbalancing}, but it takes ages to learn a strong model. The problem is that all scoring functions ($K-1$, where $K$ is number of classes) are built simultaneously and are independent. One need to make $K-1$ optimizations on each step after calculating of $|X|\times |K - 1|$ gradient values (X---training set).

Multiclass boosting allows us to split boosting process into training one weak classifier at a time balancing the weights of examples. Though one still need to solve multi-classification problem on each step which is difficult task. 

Modeling matrix approach generalize the one-vs-rest allowing one to build binary classifiers complimentary to each other. This way allows to build smaller number of decision functions than $K-1$. In this approach each binary classifier provides one bit of information on potential class of the object, combining this information we can ``decode'' the right class with much smaller number of classifiers if the binary classifier quality is high enough. The problem is that effective in terms of coding strength classifiers are often not easy to build in terms of prediction quality, especially in the case when there are many classes in dataset and obvious solutions are not effective/possible. There are some works about the building of the modeling matrix in such cases \cite{modelmatrix2,Zhao_sparseoutput}, however there is no good way to build it universally and it should be constructed in ad-hoc manner in most of the cases.

The other problem aside from learning complexity is computation difficulty of the result decision function. For instance using the heavy decision function in online environment is a challenging computational task when there are more then few dozens of classes. One vs. rest and multinomial logistic regression gives us linear decision function complexity by number of classes. With the limited time budged one have to reduce the complexity of each weighting function when number of classes grows. This reduction leads to poor classification quality in fixed time budget.

Our goal is to combine described approaches to get the method that is as simple as one-vs-rest, able to work with lot of classes, less sensitive to class imbalance, has light decision function to be used online. To achieve these properties we do the gradient boosting for multinomial logistic regression to find a decision function in form of single ensemble. The multinomial logistic regression particularly allows us to forget about class imbalance; gradient boosting allows one to control trade-off between time and model quality; and the simplicity of the decision function allows us to convert multi-classification into a series of regression tasks.

The later sections of the paper are organized as follows: in motivation part the idea of the method is explained on basis of existing approaches, the algorithm is described in details in Sec. 3., then goes experimental part of the research and finally conclusions and directions for future research are presented.

% The fo

% Our contribution as follows:
% \begin{itemize}
% \item We propose the GradFac multiclassification algorithm that is based on gradient boosting and matrix factorization. We show that in most cases it can reduce total count of weak models without sufficient quality degradation.
% \item We describe the main disadvantage of the new algorithm and propose two fixes: matrix columns bootstrapping and \emph{ElasticNet} factorization. 
% \item We apply the GradFac algorithm to the classic gradient boosted tree classifier on benchmark datasets.
% \end{itemize}



\section{Motivation}

Many algorithms in ML are dedicated to classification or regression tasks and the idea of employing them for multiclassification looks attractive. The modeling matrix approach formulated by Allwein, Schapire and Singer \cite{Allwein00reducingmulticlass} allows one to split this complex task into binary classification subtasks. Unfortunately the elements of the modeling matrix must be from set of $\{-1,0,1\}$ and this fact makes the optimization on this matrix much more difficult \cite{modelmatrix2,Zhao_sparseoutput}. We want to get rid of this limitation to simplify the optimization task. Another important property of this approach is that we can use it in case the number of classes is significant and it is next to impossible to train scoring function for each of them. In this case we ``code'' the class by modeling matrix row. Then it is possible to estimate this class probability, using results of the binary classifiers defined by each column. The minimal number of the classifiers needed to code the fixes number of classes $K$ is $log K$, and this theoretically allows us to use much less models then the number of classes. Unfortunately right coding matrix optimization is a hard task and low quality of a single classifier can ruin the quality of the whole decision function.

Our idea is to go opposite way: we want to use large set of weak models and associated with them ``coding vectors'', to get the error spread among many models on the one hand, and get a single set of weak models for all weighting functions on the other. Our method is based on classical multinomial logistic regression which we'll describe to define notation.
\subsection{Multinomial logistic regression}
The boosting of multinomial logistic regression is a well studied topic \cite{Friedman98additivelogistic}. Using previously defined $P(Y=c \arrowvert x, H)$ we can write a optimization target function in form of likelihood:
$$\begin{array}{rl}
	L(\mathbf{X} \arrowvert H) &= \sum_{(x,y) \in \mathbf{X}} \log P(Y = y \arrowvert x, H) \\
	& = \sum_{(x,y) \in \mathbf{X}} \log \frac{e^{I\{y < K\} H_y(x)}}{1+\sum_{c=1}^{K-1} e^{H_c(x)}}
	\label{eq:MLR_model}
\end{array}
$$
$\mathbf{X}$ is dataset of $(x, y)$ pairs where $x$---feature vector and $y$ is the correct class for the associated item. On each step we want $h_{t + 1}(X)$, where $X$ is a joined dataset feature matrix,
to be aligned with the $\frac{\partial L(\mathbf{X}|H)}{\partial H_c(x)}(H_t(X))$. For simplicity one can interpret 
$\frac{\partial L(X|H)}{\partial H_c(x)}(H_t(X))$ as a matrix $R_t$ of size $|X|\times K-1$. Then we optimize $h_{c,t+1}$:
\begin{equation}
h_{c,t+1} = \arg \min_h \|h_c(X) - r_{ct}\|_2^2
\label{eq:MLR_boosting_step}
\end{equation}
where $r_c$ is a column of the matrix representation of gradient $R$. At this step we need to build the regression $K-1$ times and this part is the most computationally intensive. We have described the independent variant of the optimization, but it can be enhanced even further by dropping the independence assumption for certain types of decision functions. E.g. when the CART trees are used as weak models one could build the topology of the trees independandly and then find the optimal joint leaf values solving the appropriate matrix equation.

\subsection{The idea of Factorized MultiClass Boosting}
As stated in the beginig of the section we will look for decision in the class of such functions:
\begin{equation}
H_c(x) = \sum_{t=1}^T b_{ct} h_t(x) 
\end{equation}
where $H_c(x)$ is a scoring function for class $c$ at point $x$. It consists of $T$ real-valued valued components $h_t(x)$ common for all classes. Each component is weighted for each class $c$ differently by $b_{t}$ vector values. The exact probability of the class $c$ is calculated in form of multinomial logistic regression:
\begin{equation}
P(Y = c \arrowvert x, H) = \frac{e^{I\{c < K\} H_{c}(x)}}{1+\sum_{j=1}^{K-1} e^{H_{j}(x)} }
\end{equation}
where $P(Y = c \arrowvert x, H)$ is desired probability of the class $c \in \{1\ldots K\}$ for the point $x$. This form allows us to work without conditions on $b_t$ which has $K-1$ components. One could think of $\mathbb{B} = \{b_{ct}\}$ as a ``coding matrix'' components of $\{h_t\}_t=1^T$ ensemble.

To get the right weak models $h_t$ on each step we use the boosting logic: on each step we define vector $r_t$ of ``wanted'' values for each point and find the closest weak model to this vector:
\begin{equation}
h_{t+1} = \arg \min_h \|h(X) - r_t\|.
\end{equation}
The only thing left is to find proper series of $(b_t, r_t)$. We use modification of the multinomial logistic regression gradient boosting for this. We want to optimize (\ref{eq:MLR_boosting_step}) for all classes simultaneously. Since the $l_2$ target function is additive and we can rewrite the optimization in the following form:
\begin{equation}
(h_{t+1},b_{t+1}) = \arg \min_{h,b} \sum_c \|b_ch(X) - r_{ct}\|_2^2
\end{equation}
where $b_{t+1}$---column of the future modeling matrix. We split this optimization into two steps:
\begin{equation}\begin{array}{l}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F^2 \\
h_{t+1}	= \arg \min_{h} \|h(X) - r_{t+1}\|_2^2
\end{array}\end{equation}
According to the Eckart-Young-Mirsky theorem \cite{Eckart1936} there is exact solution of the first optimization. The second one is just a regression problem.
\label{sec:fmcb_idea}

\begin{algorithm}[tb]
\caption{FMCBoosting}
\label{alg:boost_fmcb}
\begin{algorithmic}
\STATE {\bfseries Input:} step $\alpha$, iterations count $T$.
\STATE $H^{(0)}(x):= \mathbb{O} \in \mathbb{F}^{K-1}$ \COMMENT{initial zero model}
\STATE $\overline{x}^{(0)} := \mathbb{O} \in \mathbb{R}^{N \times (K-1)}$ \COMMENT{initial cursor}
 
\FOR{$t=1$ {\bfseries to} $T$}
 	\STATE Evaluate the gradient's $R_t=\nabla L(\overline{x}^{(t-1)})$ using (\ref{eq:grad_matrix}).
	\STATE Factorize the gradient's matrix:
			$$(b_{t},r_{t}) = \arg\min_{b,r} \|b r^T - R_t\|_F^2$$
	\STATE Train weak model $h_{t}(x)$ using $\{X,r^T\}$ as a training set and MSE as a target function:
 			$$h_{t+1}(x) = \arg\min_{h} \|h(X) - r_{t}\|_2^2$$  	
	\STATE Update model: $H^{(t)}(x) = H^{(t-1)}(x) + \alpha b^t h^{(t)}(x)$.
	\STATE Update cursor: $\overline{x}^{t} = \overline{x}^{(t-1)} + \alpha b^t h^{(t)}(X)$.
\ENDFOR    
\end{algorithmic}
\end{algorithm}

\section{Factorized MultiClass Boosting}

The proposed algorithm optimizes the likelihood function:
\begin{multline*}
	L(\mathbf{X} \arrowvert H) = \sum_{(x,y) \in \mathbf{X}} \log \frac{e^{I\{y < K \} H_y(x)}}{ 1+\sum_{c=1}^{K-1} e^{H_c(x)} }.
\end{multline*}
The decision takes form of vector function:
\begin{equation}
H(x) = \sum_t b_{t} h_t(x)
\end{equation}
where $b_t$ are vectors of $K-1$ components and $h_t$ are real functions of $x$. The optimization is done iteratively. $H_c(x)$ are treated as independent variables and therefore one can get gradient of target function in terms of these variables. It is possible to present this gradient vector as a matrix. Each column of it presents gradient of the appropriate class scoring function:
\begin{equation}
\label{eq:grad_matrix}
\nabla L = 
\left(
\begin{array}{ccc}
	  \frac{ \partial L }{ \partial H_{1}(x_{1}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial H_{K-1}(x_{1}) } \\

	  \vdots & \ddots & \vdots\\

	  \frac{ \partial L }{ \partial H_{1}(x_{|X|}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial H_{K-1}(x_{|X|}) }
\end{array}
\right)_{|X| \times (K-1)}
\end{equation}

Each step of optimization is done as close to the $R_t = \nabla L(H_t(X))$ as possible. To do so we factorize the matrix form of the gradient $R$ by rank $1$ matrix $b h(X)^T$ using Frobenius distance as the metric:
\begin{equation}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F^2
\label{eq:factorization_step}
\end{equation}

According to the Eckart-Young-Mirsky theorem \cite{Eckart1936}, solving (\ref{eq:factorization_step}) means finding the left and the right singular vectors of $R_t$ associated with the largest singular value of $R_t$. Therefore, one may apply the following algorithm: 
\begin{enumerate}
	\item Evaluate the singular decomposition of gradient's matrix: $R = U \Sigma V^T$
	\item Take the largest singular value $\sigma_{1}$ and associated singular vectors $u$ and $v$.
	\item Return $\overline{u}={\sigma_{1}}{\Vert v \Vert}_{2}u$ and $\overline{v}=\frac{1}{\Vert v \Vert}_{2}v$ as solution.
\end{enumerate}
In our notation $br^T = \overline{u}\overline{v}^T$. From the solutions family we choose the pair where $\|b_{t+1}\|_2 = 1$.

There are two theoretial problems with the proposed method:
\begin{itemize}
	\item in boosting process neighbor gradients are close to each other and countinous rank one factorization could become less effective;
	\item we have reduced the complexity of the learn procedure but for the SVD cost which could be even more than the original.
\end{itemize}
Experiments show that starting from some iteration, singular values become too close to each other and choice of singular vectors associated with the largest singular value becomes non-trivial. It could lead to factorization error growth because the single pair of the left and the right singular vectors is no longer a meaningful characteristic of the matrix. We call this negative effect "the spreading of singular values", as the matrix is spreading across several pairs of singular vectors. To study how to deal with this difficulty we introduce the bias on each step. See Sec.\ref{sec:bias} for details.

To overcome the computational complexity of the SVD we have implemented our variant of ALS algorithm for the matrices of special shape $m >> n$. The algorithm called StochasticALS is desctibed in Sec.\ref{sec:stochasticals}.

To find the ensemble term $h_{t+1}$ we minimize the distance with factorization component $r_{t+1}$:
\begin{equation}
h_{t+1}	= \arg \min_{h} \|h(X) - r_{t+1}\|
\label{eq:minimization_step}
\end{equation}
For our experiments we have used modification of the CART algorithm for oblivious trees \cite{Gulin_winningthe} at this step.


\paragraph{Convergence}
As stated in Sec.~\ref{sec:fmcb_idea} two step optimization of the $R_t$ does not allow us to say anything on convergence of the proposed method. The other problem is that factorization error rate is pretty high (see Fig.~\ref{fig:factorization-effectiveness}). Considering it in couple with the residual of the (\ref{eq:minimization_step}) the effective direction of the $b h_t(X)^T$ could be far from original $R_t$ and lead to $H$ quality reduction. On the other hand we have easy way to ensure that this reduction have not happen yet: if $\|R_{t+1}\|_F <\|R_{t}\|_F$ then the last step was successful. This statement could be used as a stop condition for the algorithm. In the Fig.~\ref{fig:gradient_norm} one can see the drop of the gradient norm with the iterations count for proposed modifications of the algorithm.

% \begin{figure}
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{figures/factorization_error_rate.jpg}}
% \caption{Factorization error rate growth with number of iterations of FMCB.}
% \end{center}
% \label{fig:factorization-effectiveness}
% \vskip -0.2in
% \end{figure}

\subsection{Bias in factorization}
\label{sec:bias}
\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/rel_fact_err/rel_fact_err.tex}}
\caption{Relative factorization error rate grow with the number of iterations of FMCB.}
\end{center}
\label{fig:factorization-effectiveness}
\vskip -0.2in
\end{figure}

As stated before, the intuition tells that factorization effectiveness will be reduced with each step. Fig.~\ref{fig:factorization-effectiveness} illustrates this effect on example of segment data set (see Sec.\ref{datasets} for details). Factorization gives us the best approximation of $R_t$ in class of rank 1 matrices, so we need to change the optimization goal. There are at least two different approaches to this task: introducing noise into data or biasing the solution by some prior.

\paragraph{Regularization (FMCB-EN)} % (fold)
\label{par:regularization}

% paragraph paragraph_name (end)
In this approach we are to define what kind of solutions are preferred above the others. The modeling matrix column structure gives us idea on this: each class should be either totally excluded or have positive/negative label. In our terms this means sparsity of $b_t$ vector. The most popular prior in this case is Laplacian which gives us $l_1$ regularization term in regression task. On the other hand if we let the $r$ vector grow, this regularization won't be effective because norms of these vectors are balanced. To limit the growth of $r$ we introduce normal prior and $l_2$ regularization on $r$ term. The final task takes the following form:
\begin{multline}
(b_{t+1},r_{t+1}) = \arg \min_{b,r} \|b r^T - R_t\|_F + \lambda_1 \|b\|_1 + \lambda_2 \|r\|_2
\label{eq:factorization_l1}
\end{multline}
We employ alternating least squares idea to solve (\ref{eq:factorization_l1}). Both steps of the algorithm are similar to each other, lets suppose that $r$ is fixed:
\begin{multline*}
	\hat{b} = \arg\min_{b}\|R_t-br^T\|_2^{2} + \lambda_1 \|b\|_1 + \lambda_2 \|r\|_2^2 \\
	= \arg\min_{b}\sum_{c,i}\left(R_{tci}-b_cr_i\right)^{2} + \lambda_1 \|b\|_1
	\label{eq:elastic-net-argmin}
\end{multline*}
Therefore, we have reduced the initial problem to the linear regression with either $l_1$ or $l_2$ (in case of $r$) regularization, that could be generalized to \emph{Elastic-Net}. Indeed, it can be rewritten to canonical form:
 \begin{equation*}
x^{*}=\arg\min\Vert y-Ax\Vert_{2}^{2}+\lambda_{1}\Vert x\Vert_{2}^{2}+\lambda_{2}\Vert x\Vert_{1},\label{eq:elastic-net-canon-argmin}
\end{equation*}
where $A \in \mathbb{R}^{|X|(K-1)\times |X|}$ and $y \in \mathbb{R}^{|X|(K-1)}$:
\[
A =
\begin{pmatrix}
	b_{1}     		& 				&		  \\
	\vdots			& \mathbb{O}  	&		  \\
	b_{K-1}			& 				&		  \\
					& \ddots		&		  \\
					&   			& b_{1}	  \\
					& \mathbb{O}	& \vdots  \\
					& 				& b_{K-1}
\end{pmatrix},
y=\begin{pmatrix}\begin{array}{l}
	\nabla R_{t1,1}		\\
	\vdots				\\
	\nabla R_{t1,K-1}	\\

	\vdots				\\
	
	R_{t|X|,1}		\\
	\vdots				\\
	R_{t|X|,K-1}
\end{array}\end{pmatrix}
\]
Detailed algorithm for \emph{Elastic-Net} problem could be found at \cite{Hastie_theelements} or \cite{elasticnet05}.

\paragraph{Columns sampling (FMCB-CS)}
On each iteration we "disable" random columns of the gradient's matrix by setting them to zero with probability $\frac{1}{K}$. It ensures that singular values will be "shake-up" and consequently it particularly protects us from the problem described above. However, this approach is very unstable and may cause method divergence.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/cn/cn.tex}}
\caption{Condition number of the gradient matrix during training FMCB and FMCB-EN models on \emph{pendigits} dataset.}
\end{center}
\label{fig:condition_number}
\vskip -0.2in
\end{figure}

\paragraph{Effect of the bias}
To evaluate effect of the bias introduction we track the condition number of the matrix $R_t$ which determines the quality of the factorization. The Fig.~\ref{fig:condition_number} shows the effect of our manipulations. Several first iterations are taken out from the graph because of the scaling problems (condition number is too big). As one can see, effect of bias introduction is fairy small and looking for more effective ways to deal with factorization quality degradation is one of the most promising directions of the future work. Interesting fact is that after certain number of iterations the condition number starts to grow. The norm of the gradient at that point starts to be so low, that successive iteration gradients are not aligned with each other. At that point original algorithm starts to be more precise. The problem is that this point could be not reached at some collections.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/grad_norm/gradnorm.tex}}
\caption{Gradient norm by iterations count for all proposed modifications.}
\end{center}
\label{fig:gradient_norm}
\vskip -0.2in
\end{figure}

\subsection{Stochastic ALS}\label{sec:stochasticals}
Rank one factorization is well studied topic, there are many algorithms to deal with this problem, starting from power method to more complex ALS and many other. The complexity of these algorithms is $O(K |\mathbf{X}|)$. In our case $|\mathbf{X}|$ is the number of observations which we want to grow so it is reasonable to find effective algorithm for spectial case when $K << |\mathbb{X}|$. This algorithm could be used beyound the proposed method so we will describe in general terms of matrix rank one factorization task $\arg \min_{u,v} \|A - u v^T\|$ where $A \in \mathbb{R}^{n\times m}$. In case when $m >> n$ we can turn our task to stochastic form:

\begin{equation}\begin{array}{l}
\arg \max_{(u,v)} \|A - u v^T\| = \\
\arg \max_{(u,v)} \sum_{i=1}^m \sum_{j=1}^n (a_{ij} - u_i v_j)^2 = \\
\arg \max_v E_{i \sim U(1, m)}\left(\max_{u_i} \sum_{j=1}^n (a_{ij} - u_i v_j)^2\right)
\end{array}\end{equation}
this task has infinite number of solutions because we can simultaneously scale $u$ and $v$ by any $\alpha$ and $\frac{1}{\alpha}$ to get the same result. We will look for solution where $\|v\| = 1$. One can see that the third form of the task split it to two independent optimizations of $v$ vector and for $u_i$ component of the $u$ vector. The optimal $u$ could be taken from zero derivative condition of the most internal component. $\hat{u}_i = \frac{\sum_j a_{ij}v_j}{\sum_j v_j^2}$, taking into account the unit length condition on $v$, $\hat{u_i} = \sum_j a_{ij} v_j$. And the $v$ optimization now takes the following form:
\begin{equation}\begin{array}{l}
\arg \max_{v, \|v\| = 1} E_{i \sim U(1, m)}\left(\sum_j (a_{ij} - \hat{u}_i v_j)^2\right)
\end{array}\end{equation}
This task could be easily solved by any stochastic gradient method (SGD), for memory conservation we have used the most straightforward way:
\begin{equation}\begin{array}{l}
\hat{v}_j = v_{tj} - 2 w \hat{u}_i (v_{tj} \hat{u}_i - a_{ij}) \\
v_{t+1} = Prj_{\|v\| = 1}(\hat{v})
\end{array}\end{equation}
where $w << 1$ is SGD step. The result $\hat{u}$ could be calculated after the $v$ optimization converges. This algorithm is much faster then the standard ALS on the matrices of the defined shape. When the number of observations is large and only a fixed part of this data $m$ is needed to reach low variance on weak model optimization, the complexity of the SALS algorithm drops to $O(n)$. Taking into account that our decision function is lightweight, one could conserve memory needed to store gradient boosting cursor and calculate it on demand.

\section{Experiments}\label{experiments}
Let us remind that our goal is to maximize the ratio between weak models count and prediction quality. In each experiment we compare accuracy that could be reached with fixed count of weak models. We have chosen two competing methods that could use the same weak model optimization: one vs. rest and multinomial logistic regression. This approach gives us the opportunity to compare the influence of the learning procedure but not the quality of the base/weak models.

We have tested the \emph{Factorized MultiClass Boosting} algorithm with data from the UCI repository \cite{uciRepo}. Table \ref{datasets} shows characteristics of different datasets used. Our goal was to compare proposed method and its competitors in principally different setups and chosen datasets allow us to do that.

\begin{table}[t]
\caption{Statistics for the classification datasets.}
\label{datasets}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lrrrr}
\hline
\abovespace\belowspace
Data set & Examples & Features & Classes \\
\hline
\abovespace
wine     		& 178 	& 17 	& 3     \\
letter    		& 20000 & 16 	& 26 	\\
MNIST     		& 60000 & 785 	& 10    \\
pendigits 		& 7494 	& 21 	& 10 	\\
segmentation    & 2300 	& 23 	& 7     \\
\hline
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

\input{experiments.tex}
 
The results are presented in Table 2. Each cell contains mean and standard deviation of the accuracy evaluated with 10-folds cross-validation. We find that proposed algorithm FMCB almost always achieves the highest score compared to other models. Also we see that in the most of the cases we could sufficiently reduce the weak models count for FMCB variations methods and stay competitive with state-of-the-art methods in terms of prediction quality.

\section{Conclusions and future work}
In this paper we have presented new approach to multiclass classification problem. The proposed algorithms are able to be statistically significant better than multinomial logistic regression boosting and one vs. rest using the same weak learners. This advantage persists over collections we used for testing. The number of test collections does not allow us to say that the proposed method is always better in terms of prediction quality, but we have not found evidence of the opposite statement. The resulting decision function is computationally more lightweight than one for existing methods due to its' single ensemble nature. The computational difficulty of learning procedure is on par with one vs. rest and could be optimized even further, using more effective approximate factorization techniques. FMCB method is able to work with lot of classes and the only limitation is computational complexity of the matrix form of gradient factorization procedure.

Two major problems of the proposed approach were discovered:
\begin{itemize}
	\item the factorization error rate grows with the number of iterations;
	\item because of factorization error and non zero weak optimization residual the method is able to diverge.
\end{itemize}
To overcome the first difficulty we tested two methods of bias introduction in factorization task. The tested methods were able to soften, but not to eliminate the growth of the error rate. During this testing we have found that for certain collections the discovered problem is relevant only for limited number of iterations. The second problem could be practically solved by introduction of the stop condition. We have suggested such a condition and found that we were unable to reach it on test collections.

FMCB method tends to be both easy to use, it does not require thorough data preparation, and effective in terms of computational complexity to prediction quality ratio. We hope it could be used as a ``first attempt'' method for multiclass classification tasks.

As stated before we see the following three directions of further improvements:
\begin{itemize}
	\item factorization error elimination;
	\item reduction of the factorization computational cost;
	\item applying of the presented approach in multi-label setting.
\end{itemize}
The implementation of the algorithm could be found at github \cite{github}.
% We have described our vision on first problem solutions in the paper and now focus on the second. The matrix $R_t$ often have not even dimensions. In many cases $|X| >> K$ and one can interpret factorization process in probabilistic framework:
% $$
% \hat{b} = \arg \min_b \mathbb{E}_{r \in R_t}\sum_c\left(b_c \frac{\sum_c r_c}{\sum_c b_c} - r_c\right)^2
% $$
% This optimization could be done stochastically which is less computationally difficult. Besides the computation cost this allows us not to store $R_t$ matrix which is expansive in terms of memory consumption.
% main advantage of the \emph{GradFac} algorithm is the independence of the number of classes on the training stage: it's only required to train a single model instead of $K-1$ models. However, factorization stage depends on the number of classes. 
% Consider impact of factorization on quality of the final classification model. Obviously, matrix factorization increases total error because of replacement the whole matrix to outer product of two estimated vectors $u$ and $v$. Should we decrease the algorithm's quality on purpose? To answer this question one should remember the ability of the gradient boosting method to accumulate weak models in order to obtain the strong. Therefore, to compensate introduced error, we have to increase boosting iterations count and train some additional weak models (\emph{one} per iteration). 
% Suppose $L(H_{T}(x) \arrowvert X,Y) \le \varepsilon$ is true for the source algorithm after $T_{1}$ iterations and for the \emph{GradFac} algorithm after $T_{2}$ iterations. Note that $T_{1}<T_{2}$ because we need to compensate factorization error. Also note that the source algorithm requires to train $K-1$ weak models and the \emph{GradFac} algorithm requires to train $1$ model. It's hard to say definitely which model includes less weak models count: 
% \[
% \begin{array}{rccc}
% 	\text{Iterations count:}	& T_{1} 				& <		& T_{2} \\
% 	\text{Weak models count:}	& T_{1}\times(K-1) 		& ??	& T_{2}
% \end{array}
% \]
% We will come back to this issue in the experiments section.



% We have introduced in this paper a new multiclassification algorithm GradFac that is based on the idea of gradient's matrix factorization. Experiments demonstrated that our algorithm allows to build up to 3 times easier model than state-of-the-art models like OVR or MLR without quality degradation. Of course, more experiments are needed to better understand applicability limits of this method, especially for tasks with large class count.

% There are several avenues for future research. One of the most simple ideas - variation of considering eigen vectors count (instead of 1). GradFac is also appealing for multi-label tasks because there are several target functions for such tasks \cite{Tsoumakas07multi-labelclassification} that allow to represent their gradients as matrix and consequently allow to apply factorization techniques.

% \clearpage
% Acknowledgements should only appear in the accepted version. 
% \section*{Acknowledgments} 


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\nocite{Hastie_theelements}
\nocite{GLM}
\nocite{Friedman98additivelogistic}
\nocite{Friedman00greedyfunction}
\nocite{Zhao_sparseoutput}
\nocite{Allwein00reducingmulticlass}
\nocite{Crammer00onthe}
\nocite{Rifkin04indefense}
\nocite{Lee01algorithmsfor}
\nocite{Koren09matrixfactorization}
\nocite{Hu08collaborativefiltering}
\nocite{Gulin_winningthe}
\nocite{Eckart1936}
\nocite{elasticnet05}
\nocite{Efron1992bootstrap}
%\nocite{multilabel12}
\nocite{uciRepo}

\bibliography{example_paper}
\bibliographystyle{icml2017}

\end{document} 