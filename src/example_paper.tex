%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2016 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2016,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure} 

% qdeee: for mathbb
\usepackage{amsmath}
\usepackage{amssymb}

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% For sub-files
\usepackage{standalone}

\usepackage{multicol}
\usepackage{multirow} % http://ctan.org/pkg/multirow
\usepackage{hhline} % http://ctan.org/pkg/hhline

% For plots
\usepackage{epstopdf}
%\usepackage{color}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2017} 

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
% \usepackage[accepted]{icml2017}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Using Matrix Factorization Methods for Multiclass Classification tasks}

\begin{document} 

\twocolumn[
\icmltitle{Using Matrix Factorization Methods for Multiclass Classification Tasks}
            

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2017
% package.

% list of affiliations. the first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% you can specify symbols, otherwise they are numbered in order
% ideally, you should not use this facility. affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Ruslan Solovev}{equal,to}
\icmlauthor{Igor Kuralenok}{equal,to,goo}
\end{icmlauthorlist}

\icmlaffiliation{to}{University of Torontoland, Torontoland, Canada}
\icmlaffiliation{goo}{Googol ShallowMind, New London, Michigan, USA}

\icmlcorrespondingauthor{Ruslan Solovev}{solovevr@gmail.com}
\icmlcorrespondingauthor{Igor Kuralenok}{igorkuralenok@gmail.com}


% You may provide any keywords that you 
% find helpful for describing your paper; these are used to populate 
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{multinomial logistic regression, matrix factorization, gradient boosting}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.
%\footnotetext{hi}

\begin{abstract} 
In this paper we introduce a new approach to multiclassification based on simultaneous build of weighting functions for all classes. The proposed algorithm provides more lightweight decision function while being on par with state-of-the-art methods in terms of prediction quality. The method is based on multinomial logistic regression and gradient boosting. The first part allows the researcher not to bother about balancing of different classes in dataset, and the second give her the opportunity to control the time to model quality ratio.
\end{abstract} 

\section{Introduction}
\label{introduction}
There are three basic approaches to multiclassification task: one-vs-rest, multinomial logistic regression \cite{GLM}, and using complex system of binary classifiers with associated modeling matrix \cite{Allwein00reducingmulticlass}. Each of these basis ideas have their advantages. The simplicity of one vs. rest makes it one of the most popular methods, on the other hand using this approach forces the researcher to balance class representatives in such a way that probabilities provided by different classes could be compared with each other \cite{imbalancing_classes1, imbalancing_classes2}. Multinomial logistic regression allows to build the scoring functions comparable by their design \cite{mlr_imbalancing}, but it takes ages to learn it. Modeling matrix approach generalize the one-vs-rest allowing one to build binary classifiers complimentary to each other. This way allows us to build smaller number of decision functions than the $K-1$, where $K$ is number of classes. There are some works about the building of the modeling matrix \cite{Zhao_sparseoutput, modelmatrix2}, however there is no good way to build this matrix universally and it should be constructed in ad-hoc manner in most cases.

Our first goal in this work is to combine approaches to get the method [as simple as one-vs-rest???, but ]less sensitive to class imbalance. The second goal is to get lighter decision function to be able to use it for large number of classes. To achieve these goals we employ two methods: gradient boosting for multinomial logistic regression model and matrix factorization. The multinomial logistic regression model particularly allows to forget about class imbalance; gradient boosting allows one to control the time to model quality ratio; and matrix factorization allows to reduce the count of weak models in the gradient boosting.

Our contribution as follows:
\begin{itemize}
\item We propose the GradFac multiclassification algorithm that is based on gradient boosting and matrix factorization. We show that in most cases it can reduce total count of weak models without sufficient quality degradation.
\item We describe the main disadvantage of the new algorithm and propose two fixes: matrix columns bootstrapping and \emph{ElasticNet} factorization. 
\item We apply the GradFac algorithm to the classic gradient boosted tree classifier on benchmark datasets.
\end{itemize}





\section{Multinomial logistic regression}
In this section we consider application of gradient boosting algorithm to the multinomial logistic regression problem. This application was well described by Friedman \yrcite{Friedman98additivelogistic}, so we just reformulate already known.
Assume we have a training instances set $D={(x^i, y^i)}_{i=1}^N$,  where $x\in\mathbb{R}^n$ is an instance's feature vector
and $y\in\left\{ 1,\dots,K\right\} $ is an instance's class label. According the multinomial regression model definition \cite{GLM}, we need to build the decision in the next probabilistic form:
\begin{equation}
	\mathbb{P}(Y = c \arrowvert x) =
	\begin{cases}
		\frac{ e^{s_{c}(x)} }
			 { 1+\sum_{j=1}^{K-1} e^{s_{j}(x)} }
		, & c \in \{1, \ldots, K-1 \} \\

		\frac{ 1 }
			 { 1 + \sum_{j=1}^{K-1} e^{s_{j}(x)} }
		, & c=K
	\end{cases}\label{eq:MLR_model}
\end{equation}
Here $s_{j}(x), j \in \{ 1, \ldots, K-1 \}$ are real functions (a.k.a. \textit{scoring functions}) of some class $\mathbb{F}$:
\[
	s_{j}(x): \mathbb{R}^{n} \rightarrow \mathbb{R}, j=1, \dots, K-1.
\]
Note that final decision function is fully determined by these functions.
Consider corresponding log-likelihood function for (\ref{eq:MLR_model}):
\begin{multline*}
	L(s_{1},\dots,s_{K-1} \arrowvert X) = \sum_{i=1}^{N} \ln \mathbb{P}(y_{i} \arrowvert x_{i}) =\\
	= \sum_{i=1}^{N} \ln\frac{ e^{s_{y_{i}}(x_{i})} }{ 1+\sum_{j=1}^{K-1} e^{s_{j}(x_{i})} } =\\
	= \sum_{i=1}^{N} \bigg( s_{y_{i}}(x_{i}) - \ln\bigg(1+\sum_{j=1}^{K-1}e^{s_{j}(x_{i})}\bigg) \bigg)
\end{multline*}
And the problem is formulated as follows: find $K-1$ functions $s_{1}^{*}(x),\dots,s_{K-1}^{*}(x)$ of class $\mathbb{F}$ such that
\begin{equation}
(s_{1}^{*}, \dots, s_{K-1}^{*}) = \arg\max_{s_{j} \in \mathbb{F}} L(s_{1},\dots,s_{K-1}\arrowvert X).\label{eq:argmaxL}
\end{equation}

We employ gradient boosting for solving (\ref{eq:argmaxL}).
Note that with fixed functions $s_1,\ldots,s_{K-1}$ target function $L$ becomes a $N\times(K-1)$ multivariate function of $s_1(x_1),\ldots,s_{K-1}(x_N)$ variables. Consider the gradient\footnote{Formally, the matrix notation for partial derivatives is reserved by Jacobian. We use the gradient's matrix notation for the convenience here.} of that function:
\[
\nabla L = 
\left(
\begin{array}{ccc}
	  \frac{ \partial L }{ \partial s_{1}(x_{1}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial s_{K-1}(x_{1}) } \\

	  \vdots & \ddots & \vdots\\

	  \frac{ \partial L }{ \partial s_{1}(x_{N}) } 
	& \cdots 
	& \frac{ \partial L }{ \partial s_{K-1}(x_{N}) }
\end{array}
\right)_{N \times (K-1)}
\]
Partial derivatives of $L$ are:
\begin{multline}
\frac{ \partial L }{ \partial s_{j}(x_{i}) }=
\frac{ \partial L(s_{1}(x_{i}),\dots,s_{K-1}(x_{i})) }{ \partial s_{j}(x_{i}) }= \\ =
\frac{ e^{s_{j}(x_{i})} }{ 1+\sum_{k=1}^{K-1} e^{s_{k}(x_{i})} } - I\{y_{i} = j\} \label{eq:partial_L}
\end{multline}
According the gradient boosting algorithm, on each iteration we have to train a L2-approximation of gradient of the target function. Therefore, we have to train $K-1$ approximation models: one  model per each column of the gradient matrix. See Algorithm~\ref{alg:boost_mlr} for details.


\begin{algorithm}[tb]
   \caption{Gradient boosting for MLR}
   \label{alg:boost_mlr}
\begin{algorithmic}
   \STATE {\bfseries Input:} step $\alpha$, iterations count $T$.
   \STATE $H^{(0)}(x):= \mathbb{O} \in \mathbb{F}^{K-1}$ \COMMENT{initial zero model}
   \STATE $\overline{x}^{(0)} := \mathbb{O} \in \mathbb{R}^{N \times (K-1)}$ \COMMENT{initial cursor}

   \FOR{$t=1$ {\bfseries to} $T$}
   		\STATE Evaluate $\nabla L$ at $\overline{x}^{(t-1)}$ using (\ref{eq:partial_L}).
   		\FOR{$j=1$ {\bfseries to} $K-1$}
   			\STATE Train weak model $h_{j}^{(t)}(x)$ using $\{X,\nabla L^{[j]}\}$ as a training set and MSE as a target function:
   			\[
				h_{j}^{(t)}(x)=\arg\min_{h \in \mathbb{F}} \sum_{i=1}^{N}\left(\nabla L_{ij}-h(x_{i})\right)^{2}
			\]
		\ENDFOR
		\STATE Update model: $H^{(t)}(x)=H^{(t-1)}(x)+\alpha h^{(t)}(x)$.
		\STATE Update cursor: $\overline{x}^{t} = \overline{x}^{(t-1)} + h^{(t)}(X)$.
   \ENDFOR
   
\end{algorithmic}
\end{algorithm}


\section{GradFac}

\subsection{Motivation}
We will look for decision function in the class of the following functions:
$$
H_c(x) = \sum_t b_{ct} h_t(x) 
$$
where $H_c(x)$ is a scoring function for class $c$ at point $x$, $b_c$ is scalar value, associated with the class $c$ at step $t$, and $h_t(x)$ is some real-valued function of $x$. The probability of class $c$ will look exactly like one in multinomial logistic regression:
\begin{equation}
  P(Y = c \arrowvert x, H) =
  \begin{cases}
    \frac{ e^{H_{c}(x)} }
       { 1+\sum_{j=1}^{K-1} e^{H_{j}(x)} }
    , & c \in \{1, \ldots, K-1 \} \\

    \frac{ 1 }
       { 1 + \sum_{j=1}^{K-1} e^{H_{j}(x)} }
    , & c=K
  \end{cases}
\end{equation}
This type of decision function look very similar to those using modeling matrix, the difference is that we use real values instead of those from $\{-1,0,1\}$ set in modeling matrix $\mathbb{B} = \{b_{ct}\}$ and will build regression on each step instead of classification.

To build a sequence of $b_t$ and $h_t$ we use the idea of Friedman's gradient boosting. The target function we use is likelihood of the data based on introduced probability $P(Y = c \arrowvert x, H)$:
$$
\hat{H}(x) = \arg \min_H \sum_{(x,y) \in X} \log P(Y = c \arrowvert x, H)
$$
where $(x,y)$ is an example coming from training set $X$, $H$---vector of size $k-1$. On each step we build a weak model $(b_t, h_)$ to be as close to likelihood gradient matrix $\frac{\partial L}{\partial H_c(x)}\left(X\right)$ as possible:

$$
(b_t, h_t) = \arg \min_{b,h} \left\|\frac{\partial L}{\partial H_c(x)}\left(X\right) - b_t h_t(X)\right\|_F
$$


%Unfortunately in this case we are unable to use direct factorization of the gradient matrix. With each step the condition number of the matrix will lower because the step $b_t h_t(x)$ is close to major eigen vector. Reduction of the condition number will lower the effectiveness of factorization with each step. To overcome this difficulty we have introduced the bias on each step. In the following chapters we will implement the bias in form of prior (and appropriate regularization) and introducion of the noise into data.





% In the previous section we have shown the application of gradient boosting method to the multinomial logistic regression problem. One of the main disadvantages of this approach is model complexity. For example, if one is solving the multiclass problem with $K$ classes using gradient boosting with $T$ iterations, then total model count will be equal to $T \times (K-1)$. In practice, the number of boosting iterations is measured in thousands [cite YetiRank]. Consequently, in case of the problem with 100 classes total weak models count will be measured in hundreds of thousands.

\subsection{Main idea}
Algorithm~\ref{alg:boost_mlr} allows to build an approximation of the gradient's matrix as the set of $h_j(x)$ functions:
\[
	\nabla L \approx
	\begin{pmatrix}
		h_{1}(x_{1}) & \cdots & h_{K-1}(x_{1}) \\
			  \vdots & \ddots & \vdots \\
		h_{1}(x_{N}) & \cdots & h_{K-1}(x_{N})
	\end{pmatrix}_{N\times(K-1)}
\]

We employ matrix factorization to reduce the set of functions to the single function. Consider rank-1 approximation of the $\nabla L$ matrix:
\[
	\nabla L \approx \overline{u} \, \overline{v}^{T}, u \in \mathbb{R}^{N},v \in \mathbb{R}^{K-1},
\]
where
\begin{equation}
	\overline{u},\overline{v} =
	\arg\min_{u, v} \sum_{i,j}(\nabla L_{ij}-uv)^{2}. \label{eq:mx_approx}
\end{equation}
Given the real vector $\overline{u}$, we can train weak model on that:
\[
	u(x) = \arg\min_{u \in \mathbb{F}} \sum_{i=1}^{N}\left(\overline{u}_i-u(x_{i})\right)^{2}.
\]
Desired functions $h_{1}(x),\dots,h_{K-1}(x)$ could be expressed as a product of $u(x)$ and corresponding j-th element of the constant vector $\overline{v}$:
\[
h_{j}(x)=u(x)\cdot\overline{v}_{j}.
\]
Therefore, the actual gradient's matrix approximation could be written as follows:
\[
	\nabla L \approx
	\begin{pmatrix}
		u(x_{1})\cdot\overline{v}_{1} & \cdots & u(x_{1})\cdot\overline{v}_{K-1} \\
							   \vdots & \ddots & \vdots \\
		u(x_{N})\cdot\overline{v}_{1} & \cdots & u(x_{N})\cdot\overline{v}_{K-1}
	\end{pmatrix}_{N\times(K-1)}
\]
Now we can rewrite the weak models training stage in Algorithm~\ref{alg:boost_mlr}:
\begin{enumerate}
\item Factorize the gradient's matrix:
\[
\overline{u},\overline{v} = \arg\min_{u,v}\sum_{i,j}(\nabla L_{ij}-u_{i}v_{j})^{2}.
\]

\item Train a weak model on the vector $\overline{u}$: \label{eq:u_train}
\begin{equation}
	u(x)=\arg\min_{u\in F}\sum_{i=1}^{N}\left(\overline{u}-u(x_{i})\right)^{2}.
\end{equation}

\item Compose vector function $h(x)$:
\[
	h(x) =
	(u(x)\cdot\overline{v}_{1},\dots,u(x)\cdot\overline{v}_{K-1})=u(x)\overline{v}.
\]
\end{enumerate}
Note that (\ref{eq:mx_approx}) may be effectively solved by ALS\cite{Hu08collaborativefiltering}.


\subsection{Matrix factorization}
(This problem could be efficiently solved by \emph{alternating least squares} method \cite{Hu08collaborativefiltering}.)

According to the Eckart-Young-Mirsky theorem \cite{Eckart1936}, solving (\ref{eq:mx_approx}) means finding the left and the right singular vectors of $\nabla L$ associated with the largest singular value of $\nabla L$. Therefore, one may apply the next algorithm for solving this problem: 
\begin{enumerate}
	\item Evaluate the singular decomposition of gradient's matrix: $\nabla L = U \Sigma V^T$
	\item Take the largest singular value $\sigma_{1}$ and associated singular vectors $u$ and $v$.
	\item Return $\overline{u}={\sigma_{1}}{\Vert v \Vert}_{2}u$ and $\overline{v}=\frac{1}{\Vert v \Vert}_{2}v$ as solution.
\end{enumerate}
However, experiments show that starting from the some iteration, singular values become too close to each other and choice of singular vectors associated with the largest singular value becomes non-trivial. It leads to factorization error growth because the single pair of the left and the right singular vectors is no longer meaningful characteristic of the matrix. We call this negative effect "the spreading of singular values", as the matrix is spreading across several pairs of singular vectors.
To deal with this effect we propose two methods: regularized factorization and columns bootstrap.

\subsubsection{Regularization}
Instead of solving (\ref{eq:mx_approx}), consider the next problem:
\begin{multline}
	u^{*}, v^{*} = \arg\min_{u,v}\sum_{i,j}\left(\nabla L_{ij}-u_{i}v_{j}\right)^{2} + \\
	+\alpha_{1} \Vert u\Vert_{1} + \alpha_{2} \Vert u\Vert_{2}^{2} 
	+\beta_{1}  \Vert v\Vert_{1} + \beta_{2}  \Vert v\Vert_{2}^{2}. \label{eq:def-argmin-elasticnet}
\end{multline}
Added terms are called \emph{Elastic-Net regularization} for (\ref{eq:mx_approx}) \cite{elasticnet05}. Usually similar problems are considered for non-negative matrix factorization \cite{MahNMF},\cite{another-nmf-with-en}, however we don't need such constraint.

We employ alternating iterations idea [ref to ALS] for solving (\ref{eq:def-argmin-elasticnet}). For example, consider (\ref{eq:def-argmin-elasticnet}) with fixed $\overline{v}$. Then:
\begin{multline*}
	u^{*} = \arg\min_{u}\sum_{i,j}\left(\nabla L_{ij}-u_{i}\overline{v}_{j}\right)^{2} + \\
	+ \alpha_{1}\Vert u\Vert_{1}+\alpha_{2}\Vert u\Vert_{2}^{2}
	+ \beta_{1}\Vert\overline{v}\Vert_{1}+\beta_{2}\Vert\overline{v}\Vert_{2}^{2} = \\
	= \arg\min_{u}\sum_{i,j}\left(\nabla L_{ij}-u_{i}\overline{v}_{j}\right)^{2}
	+ \alpha_{1}\Vert u\Vert_{1}+\alpha_{2}\Vert u\Vert_{2}^{2}
	\label{eq:elastic-net-argmin}
\end{multline*}
Therefore, we have reduced the source problem to the linear regression problem with \emph{Elastic-Net} regularization. Indeed, we can rewrite it in canonical form:
 \begin{equation*}
x^{*}=\arg\min\Vert y-Ax\Vert_{2}^{2}+\alpha_{1}\Vert x\Vert_{2}^{2}+\alpha_{2}\Vert x\Vert_{1},\label{eq:elastic-net-canon-argmin}
\end{equation*}
where $A \in \mathbb{R}^{N(K-1)\times N}$ and $y \in \mathbb{R}^{N(K-1)}$:
\[
A =
\begin{pmatrix}
	v_{1}     		& 				&		  \\
	\vdots			& \mathbb{O}  	&		  \\
	v_{K-1}			& 				&		  \\
					& \ddots		&		  \\
					&   			& v_{1}	  \\
					& \mathbb{O}	& \vdots  \\
					& 				& v_{K-1}
\end{pmatrix},
y=\begin{pmatrix}\begin{array}{l}
	\nabla L_{1,1}		\\
	\vdots				\\
	\nabla L_{1,K-1}	\\

	\vdots				\\
	
	\nabla L_{N,1}		\\
	\vdots				\\
	\nabla L_{N,K-1}
\end{array}\end{pmatrix}
\]
Detailed algorithm for \emph{Elastic-Net} problem could be found at \cite{elasticnet05} or \cite{Hastie_theelements}. 

Similarly, one could derive the linear system in case of fixed vector $u$. Hence, the final algorithm is similar to ALS but instead of alternating gradient steps one needs to alternate solving \emph{Elastic-Net} problem. Due to the simple structure of matrix $A$, these problems could be solved very efficiently.

\begin{figure}
\vskip 0.2in
\begin{center}
\centerline{\includegraphics[width=\columnwidth]{figures/cn.tex}}
\caption{Condition number of the gradient matrix during training GF and GFEN models on \emph{segmentation} dataset.}
\end{center}
\vskip -0.2in
\end{figure}

\subsubsection{Columns bootstrapping}
We employ statistical bootstrap idea \cite{Efron1992bootstrap}. On each iteration we assign random integer weights to columns of the gradient's matrix. It ensures that singular values will be "shake-up" and consequently it particularly protects us from the problem described above. Required weights could be generated by discrete random variable $\xi$ that has a Poisson distribution with $\lambda = 1$. Due to the fact that $\mathbb{E} \xi = 1$, this weighing approach has a simple physical meaning: in the most of cases we consider all columns of the gradient's matrix but sometimes we amplify ($\xi > 1$) or mute ($\xi = 0$) some of them.


\section{Discussion}
The main advantage of the \emph{GradFac} algorithm is the independence of the number of classes on the training stage: it's only required to train a single model instead of $K-1$ models. However, factorization stage depends on the number of classes. 
Consider impact of factorization on quality of the final classification model. Obviously, matrix factorization increases total error because of replacement the whole matrix to outer product of two estimated vectors $u$ and $v$. Should we decrease the algorithm's quality on purpose? To answer this question one should remember the ability of the gradient boosting method to accumulate weak models in order to obtain the strong. Therefore, to compensate introduced error, we have to increase boosting iterations count and train some additional weak models (\emph{one} per iteration). 
Suppose $L(H_{T}(x) \arrowvert X,Y) \le \varepsilon$ is true for the source algorithm after $T_{1}$ iterations and for the \emph{GradFac} algorithm after $T_{2}$ iterations. Note that $T_{1}<T_{2}$ because we need to compensate factorization error. Also note that the source algorithm requires to train $K-1$ weak models and the \emph{GradFac} algorithm requires to train $1$ model. It's hard to say definitely which model includes less weak models count: 
\[
\begin{array}{rccc}
	\text{Iterations count:}	& T_{1} 				& <		& T_{2} \\
	\text{Weak models count:}	& T_{1}\times(K-1) 		& ??	& T_{2}
\end{array}
\]
We will come back to this issue in the experiments section.

\section{Experiments} \label{experiments}
We have tested the \emph{GradFac} algorithm with natural data from the UCI repository \cite{uciRepo}. Table \ref{datasets} shows characteristics of different datasets used.

\begin{table}[t]
\caption{Statistics for the classification datasets.}
\label{datasets}
\vskip 0.15in
\begin{center}
\begin{small}
\begin{sc}
\begin{tabular}{lrrrr}
\hline
\abovespace\belowspace
Data set & Examples & Features & Classes \\
\hline
\abovespace
wine     		& 178 	& 17 	& 3     \\
letter    		& 20000 & 16 	& 26 	\\
MNIST     		& 60000 & 785 	& 10    \\
pendigits 		& 7494 	& 21 	& 8 	\\
segmentation    & 2300 	& 23 	& 6     \\
\hline
\end{tabular}
\end{sc}
\end{small}
\end{center}
\vskip -0.1in
\end{table}

\input{experiments.tex}
 
\subsection{Experimental setup}
Let us remind that our main goal is minimization of the total weak models count. In each experiment we compare micro-$F_1$-score that could be reached with fixed count of weak models. 

All considered models are multinomial logistic regression models that were trained with gradient boosting method. We use oblivious decision tree with depth = 6 [ref] as a weak model. The main difference between compared models is learning method for scoring functions $h_{j}(x)$ on each iteration of the gradient boosting algorithm. We consider three learning methods:
\begin{enumerate}
	\item Multinomial logistic regression. For each j-th column of the gradient's matrix we train separate decision tree and use this tree as $h_{j}(x)$.

	\item \emph{GradFac}. Using ALS we factorize the gradient's matrix to product of two vectors $\overline{u}$ and $\overline{v}$. The scoring function $h_{j}(x)$ is expressed as a product of $u(x)$ and $\overline{v}_{j}$, where $u(x)$ is a decision tree trained on vector $\overline{u}$.

	\item \emph{GradFac} with \emph{Elastic-Net} regularization. Similar to previous, but factorization is performed via alternating of \emph{Elastic-Net} problems.
\end{enumerate}
Also we include classic one-vs-rest approach to comparison. For each class we train binary logistic regression model with gradient boosting method. Again, we use oblivious decision tree with depth = 6 as a  weak model.


\subsection{Results}
The results are presented in Table 2. Each cell contains mean and standard deviation of the micro-$F_1$-score which evaluated with 10-folds cross-validation. We find that our proposed algorithm GFEN almost always achieves the highest $F_1$-score compared to other models. Also we see that in most cases we could sufficiently reduce the weak models count for GFEN or GF methods and stay competitive with state-of-the-art methods like MLR or OVR.


\section{Conclusion}
We have introduced in this paper a new multiclassification algorithm GradFac that is based on the idea of gradient's matrix factorization. Experiments demonstrated that our algorithm allows to build up to 3 times easier model than state-of-the-art models like OVR or MLR without quality degradation. Of course, more experiments are needed to better understand applicability limits of this method, especially for tasks with large class count.

There are several avenues for future research. One of the most simple ideas - variation of considering eigen vectors count (instead of 1). GradFac is also appealing for multi-label tasks because there are several target functions for such tasks \cite{Tsoumakas07multi-labelclassification} that allow to represent their gradients as matrix and consequently allow to apply factorization techniques.

% \clearpage
% Acknowledgements should only appear in the accepted version. 
\section*{Acknowledgments} 


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
%\nocite{langley00}

\nocite{Hastie_theelements}
\nocite{GLM}
\nocite{Friedman98additivelogistic}
\nocite{Friedman00greedyfunction}
\nocite{Zhao_sparseoutput}
\nocite{Allwein00reducingmulticlass}
\nocite{Crammer00onthe}
\nocite{Rifkin04indefense}
\nocite{Lee01algorithmsfor}
\nocite{Koren09matrixfactorization}
\nocite{Hu08collaborativefiltering}
\nocite{Gulin_winningthe}
\nocite{Eckart1936}
\nocite{elasticnet05}
\nocite{Efron1992bootstrap}
%\nocite{multilabel12}
\nocite{uciRepo}

\bibliography{example_paper}
\bibliographystyle{icml2017}

\end{document} 