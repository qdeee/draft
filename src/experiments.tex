\documentclass{standalone}

\begin{document}

% what's going on here: we have 5 tables with detailed results for 4 models: mll, gf, gfen, ovr. 

% Format:
% trees	mll_scores
%		gf_scores
%		gfen_scores
%		ovr_scores
%
% where scores have format: (mf_mean+mf_std [mf_low_ci, mf_high_ci]) / (MF_mean+MF_std [MF_low_ci, MF_high_ci])
% (mf - micro_f1, MF - macro_f1)

% ./letters/table
% models	mll	gf	gfen	ovr
% 3120	(0.914822+0.005035 [0.911918, 0.917485]) / (0.915615+0.005467 [0.911969, 0.918473])
% 		(0.946169+0.005010 [0.941041, 0.948078]) / (0.946278+0.004943 [0.941958, 0.948450])
% 		(0.946777+0.001795 [0.945645, 0.947726]) / (0.947035+0.001689 [0.945966, 0.947933])
% 		(0.921943+0.005899 [0.918363, 0.925238]) / (0.922707+0.005990 [0.919316, 0.926178])

% 6240 	(0.933456+0.003572 [0.931149, 0.935462]) / (0.933770+0.003819 [0.931251, 0.935766])
% 		(0.957867+0.004170 [0.955297, 0.960067]) / (0.957763+0.004111 [0.955000, 0.959936])
% 		(0.958166+0.003105 [0.956169, 0.959777]) / (0.958205+0.002980 [0.956347, 0.959789])
% 		(0.943438+0.004180 [0.940277, 0.945539]) / (0.943637+0.004080 [0.940802, 0.945865])

% 9100 	(0.940391+0.004779 [0.937782, 0.943342]) / (0.940551+0.004921 [0.937378, 0.943559])
% 		(0.960252+0.004313 [0.957661, 0.962672]) / (0.960131+0.004205 [0.957312, 0.962447])
% 		(0.962153+0.003978 [0.959672, 0.964203]) / (0.962191+0.003894 [0.959684, 0.964345])
% 		(0.949729+0.003861 [0.947195, 0.951839]) / (0.949843+0.003851 [0.947554, 0.951811])
%
%
% ./mnist/table
% models	mll	gf	gfen	ovr
% 1300	(0.952298+0.002039 [0.950951, 0.953415]) / (0.951944+0.002199 [0.950622, 0.953087])
% 		(0.963547+0.001552 [0.962680, 0.964472]) / (0.963269+0.001584 [0.962389, 0.964150])
% 		(0.963399+0.002231 [0.962294, 0.964944]) / (0.963132+0.002305 [0.962024, 0.964707])
% 		(0.956639+0.001884 [0.955551, 0.957643]) / (0.956340+0.001933 [0.955231, 0.957387])
%
% 2600	(0.962831+0.001699 [0.962050, 0.964088]) / (0.962553+0.001814 [0.961614, 0.963935])
% 		(0.969786+0.001350 [0.968934, 0.970576]) / (0.969594+0.001367 [0.968732, 0.970388])
% 		(0.970315+0.001913 [0.969208, 0.971365]) / (0.970097+0.001961 [0.969039, 0.971306])
% 		(0.966071+0.001519 [0.965120, 0.966883]) / (0.965867+0.001573 [0.964918, 0.966798])
%
% 4000	(0.967199+0.001689 [0.966281, 0.968246]) / (0.966944+0.001746 [0.965954, 0.967985])
% 		(0.972119+0.001390 [0.971332, 0.972956]) / (0.971953+0.001411 [0.971169, 0.972880])
% 		(0.973041+0.001845 [0.972067, 0.974220]) / (0.972860+0.001919 [0.971871, 0.974137])
% 		(0.970321+0.001420 [0.969258, 0.971026]) / (0.970148+0.001494 [0.969143, 0.970938])
%
%
% ./pendigits/table
% models	mll	gf	gfen	ovr
% 1300 	(0.987849+0.003195 [0.985768, 0.989564]) / (0.987961+0.003097 [0.986129, 0.989690])
% 		(0.990757+0.003586 [0.988916, 0.993002]) / (0.990934+0.003606 [0.989115, 0.993310])
% 		(0.991691+0.002887 [0.990033, 0.993393]) / (0.991835+0.002902 [0.990155, 0.993538])
% 		(0.990381+0.002695 [0.988877, 0.992011]) / (0.990605+0.002694 [0.988918, 0.992193])

% 2600 	(0.990120+0.002764 [0.988160, 0.991515]) / (0.990199+0.002694 [0.988454, 0.991553])
% 		(0.992091+0.003515 [0.990314, 0.994505]) / (0.992210+0.003566 [0.990215, 0.994266])
% 		(0.992899+0.003129 [0.991190, 0.994921]) / (0.992982+0.003196 [0.991118, 0.994934])
% 		(0.991193+0.002202 [0.989883, 0.992503]) / (0.991387+0.002196 [0.990171, 0.992635])

% 4000 	(0.990920+0.002580 [0.989103, 0.992266]) / (0.991033+0.002504 [0.989523, 0.992301])
% 		(0.992492+0.003497 [0.990842, 0.994948]) / (0.992633+0.003522 [0.990724, 0.995013])
% 		(0.993165+0.003205 [0.991293, 0.995172]) / (0.993283+0.003266 [0.991238, 0.995244])
% 		(0.991592+0.001804 [0.990603, 0.992715]) / (0.991750+0.001847 [0.990752, 0.992981])
%
%
% ./segment/table
% models	mll	gf	gfen	ovr
% 490 	(0.980592+0.010208 [0.974959, 0.986503]) / (0.980757+0.009923 [0.975127, 0.986661])
% 		(0.983644+0.008410 [0.979058, 0.988461]) / (0.984047+0.007319 [0.979819, 0.988265])
% 		(0.985342+0.007251 [0.981135, 0.989298]) / (0.986007+0.006244 [0.982566, 0.990045])
% 		(0.977452+0.008241 [0.973425, 0.983266]) / (0.977640+0.008533 [0.973782, 0.983643])

% 1050 	(0.981906+0.008462 [0.977106, 0.987422]) / (0.982009+0.008565 [0.977393, 0.987619])
% 		(0.984063+0.007776 [0.979216, 0.988166]) / (0.984386+0.006915 [0.980569, 0.988273])
% 		(0.985749+0.007579 [0.981013, 0.989848]) / (0.986255+0.006530 [0.982097, 0.989978])
% 		(0.979655+0.008432 [0.974750, 0.984958]) / (0.979733+0.008863 [0.974777, 0.985046])

% 1750 	(0.981823+0.009336 [0.976495, 0.987683]) / (0.981843+0.009565 [0.976761, 0.987241])
% 		(0.985325+0.007602 [0.980448, 0.989503]) / (0.985692+0.006752 [0.981548, 0.989411])
% 		(0.985749+0.007579 [0.980495, 0.989627]) / (0.986255+0.006530 [0.981428, 0.989473])
% 		(0.981379+0.007905 [0.976002, 0.985521]) / (0.981574+0.008253 [0.976158, 0.985744])
%
%
% ./wine/table
% models	mll	gf	gfen	ovr
% 30	(0.948882+0.046854 [0.923803, 0.975400]) / (0.947801+0.047724 [0.921972, 0.976582])
% 		(0.947671+0.040697 [0.925487, 0.970770]) / (0.925152+0.105859 [0.810031, 0.966517])
% 		(0.931409+0.050906 [0.900136, 0.959113]) / (0.909683+0.104691 [0.813619, 0.951616])
% 		(0.944808+0.084621 [0.881960, 0.984127]) / (0.951091+0.073016 [0.892577, 0.984604])

% 60	(0.969570+0.036525 [0.943902, 0.988235]) / (0.972358+0.034144 [0.946635, 0.987293])
% 		(0.967433+0.038717 [0.940616, 0.986425]) / (0.969948+0.035840 [0.945056, 0.987754])
% 		(0.954875+0.059847 [0.909626, 0.980912]) / (0.958142+0.054466 [0.914815, 0.984109])
% 		(0.950690+0.066832 [0.899690, 0.979365]) / (0.953682+0.059857 [0.910496, 0.981186])

% 90	(0.975126+0.036504 [0.946784, 0.992593]) / (0.976593+0.034738 [0.948554, 0.992172])
% 		(0.969243+0.046068 [0.937248, 0.991534]) / (0.970620+0.043485 [0.937444, 0.989167])
% 		(0.954875+0.059847 [0.905637, 0.982066]) / (0.958142+0.054466 [0.924120, 0.984178])
% 		(0.955452+0.068638 [0.898813, 0.988889]) / (0.958565+0.061596 [0.911335, 0.986070])



\begin{table*}%[t]
\label{exp-results}
\centering
\caption{Micro-averaged $F_{1}$ scores for the multinomial logistic regression (MLR), factorized multiclass boosting (FMCB), factorized multiclass boosting with elastic-net (FMCB-EN), factorized multiclass boosting with columns sampling (FMCB-CS), One-vs-Rest (OVR) models on benchmark datasets.}
\vskip 0.15in
\begin{small}
\begin{sc}
{\renewcommand{\arraystretch}{1.2}% for the vertical padding
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
\abovespace\belowspace
Dataset		& \# Models 	& MLR & FMCB & FMCB-EN 	& FMCB-CS & OVR  \\
\hline\hline
\multirow{3}{*}{wine}
	& 30    		& 0.949 $\pm$ 0.047 		 & 0.948 $\pm$ 0.041 & 0.931 $\pm$ 0.051 & \textbf{0.956 $\pm$ 0.002} & 0.945 $\pm$ 0.085\\
	& 60	  		& \textbf{0.970 $\pm$ 0.037} & 0.967 $\pm$ 0.039 & 0.955 $\pm$ 0.060 & 0.956 $\pm$ 0.002 & 0.951 $\pm$ 0.067\\
	& 90    		& \textbf{0.975 $\pm$ 0.037} & 0.969 $\pm$ 0.046 & 0.955 $\pm$ 0.060 & 0.963 $\pm$ 0.002 & 0.955 $\pm$ 0.069\\
\hline
\multirow{3}{*}{letters}
	& 3120			& 0.915 $\pm$ 0.005 & 0.946 $\pm$ 0.005 & \textbf{0.947 $\pm$ 0.002} & 0.947 $\pm$ 0.003 & 0.922 $\pm$ 0.006\\
	& 6240	 		& 0.933 $\pm$ 0.004 & 0.958 $\pm$ 0.004 & \textbf{0.958 $\pm$ 0.003} & 0.958 $\pm$ 0.003 & 0.943 $\pm$ 0.004\\
	& 9100 			& 0.940 $\pm$ 0.005 & 0.960 $\pm$ 0.004 & \textbf{0.962 $\pm$ 0.004} & 0.961 $\pm$ 0.004 & 0.950 $\pm$ 0.004\\
\hline
\multirow{3}{*}{mnist}
	& 1300			& 0.952 $\pm$ 0.002 & 0.964 $\pm$ 0.002 			& 0.963 $\pm$ 0.002 			& \textbf{0.964 $\pm$ 0.002} & 0.957 $\pm$ 0.002\\
	& 2600			& 0.963 $\pm$ 0.002 & 0.970 $\pm$ 0.001 	& 0.970 $\pm$ 0.002 			& \textbf{0.971 $\pm$ 0.002} & 0.966 $\pm$ 0.002\\
	& 4000			& 0.967 $\pm$ 0.002 & 0.972 $\pm$ 0.001 			& 0.973 $\pm$ 0.002 	& \textbf{0.973 $\pm$ 0.002} & 0.970 $\pm$ 0.001\\
\hline
\multirow{3}{*}{pendigits}
	& 1300			& 0.988 $\pm$ 0.003 & 0.991 $\pm$ 0.004 & \textbf{0.992 $\pm$ 0.003} & 0.991 $\pm$ 0.003 & 0.990 $\pm$ 0.003 \\
	& 2600			& 0.990 $\pm$ 0.003 & 0.992 $\pm$ 0.004 & \textbf{0.993 $\pm$ 0.003} & 0.992 $\pm$ 0.003 & 0.991 $\pm$ 0.002 \\
	& 4000			& 0.991 $\pm$ 0.003 & 0.992 $\pm$ 0.003 & \textbf{0.993 $\pm$ 0.003} & 0.992 $\pm$ 0.004 & 0.992 $\pm$ 0.002 \\
\hline
\multirow{3}{*}{segmentation}
	& 490			& 	0.981 $\pm$ 0.010 & 0.984 $\pm$ 0.008 & \textbf{0.985 $\pm$ 0.007} & 0.974 $\pm$ 0.003 & 0.977 $\pm$ 0.008 \\
	& 1050			& 	0.982 $\pm$ 0.008 & 0.984 $\pm$ 0.008 & \textbf{0.986 $\pm$ 0.008} & 0.975 $\pm$ 0.004 & 0.980 $\pm$ 0.008 \\
	& 1750			& 	0.982 $\pm$ 0.009 & 0.985 $\pm$ 0.008 & \textbf{0.987 $\pm$ 0.008} & 0.975 $\pm$ 0.004 & 0.981 $\pm$ 0.008 \\
\hline
\end{tabular}
\vskip -0.1in
} % {\renewcommand{\arraystretch}{1.2}% for the vertical padding
\end{sc}
\end{small}
\end{table*}
	





\end{document}